{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f38fb3c-f45f-4a1e-bff5-fe3cd00c5347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.1-cp310-cp310-win_amd64.whl (9.3 MB)\n",
      "                                              0.0/9.3 MB ? eta -:--:--\n",
      "                                              0.0/9.3 MB ? eta -:--:--\n",
      "     -                                        0.3/9.3 MB 2.0 MB/s eta 0:00:05\n",
      "     --                                       0.5/9.3 MB 3.1 MB/s eta 0:00:03\n",
      "     ---                                      0.9/9.3 MB 4.0 MB/s eta 0:00:03\n",
      "     -----                                    1.4/9.3 MB 5.1 MB/s eta 0:00:02\n",
      "     --------                                 1.9/9.3 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------                               2.4/9.3 MB 6.7 MB/s eta 0:00:02\n",
      "     ------------                             3.0/9.3 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------                          3.5/9.3 MB 7.6 MB/s eta 0:00:01\n",
      "     -----------------                        4.0/9.3 MB 7.9 MB/s eta 0:00:01\n",
      "     -------------------                      4.5/9.3 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------                    5.0/9.3 MB 8.3 MB/s eta 0:00:01\n",
      "     -----------------------                  5.4/9.3 MB 8.5 MB/s eta 0:00:01\n",
      "     -----------------------                  5.5/9.3 MB 8.5 MB/s eta 0:00:01\n",
      "     -----------------------                  5.5/9.3 MB 8.5 MB/s eta 0:00:01\n",
      "     -------------------------                6.0/9.3 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------              6.4/9.3 MB 7.7 MB/s eta 0:00:01\n",
      "     --------------------------------         7.5/9.3 MB 8.9 MB/s eta 0:00:01\n",
      "     ----------------------------------       8.0/9.3 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     8.5/9.3 MB 8.8 MB/s eta 0:00:01\n",
      "     --------------------------------------   9.0/9.3 MB 8.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.3 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.3 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.3 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.2/9.3 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.3/9.3 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "                                              0.0/302.2 kB ? eta -:--:--\n",
      "     -------------------------------------  297.0/302.2 kB 9.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 302.2/302.2 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.1 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26e6cb1-50d8-4551-be1c-ebf068bcb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0322c47-ccc2-4f65-866b-3dbe0065a3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223544</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>:Jerome, I see you never got around to this…! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223545</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223546</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223547</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223548</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223549 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "223544  fff8f64043129fa2  :Jerome, I see you never got around to this…! ...   \n",
       "223545  fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...   \n",
       "223546  fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...   \n",
       "223547  fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...   \n",
       "223548  fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "223544      0             0        0       0       0              0  \n",
       "223545      0             0        0       0       0              0  \n",
       "223546      0             0        0       0       0              0  \n",
       "223547      1             0        1       0       1              0  \n",
       "223548      0             0        0       0       0              0  \n",
       "\n",
       "[223549 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv(\"jigsaw-toxic-comment-train.csv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae8d42b-d69d-46b8-bea3-4a37604c1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = d['comment_text']\n",
    "y = d[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a290bf55-8865-40dc-ab10-ebd8e7e20fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorization of text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the number of features as needed\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365328a-7d30-434c-a3af-f57ad96c5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ef54e8b-7791-4cec-9313-9c3338c989e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "887c7d40-fa43-4bc5-980b-d39e98983d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GRU model\n",
    "gru_model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=5000, output_dim=128, input_length=X_train_tfidf.shape[1]),\n",
    "    keras.layers.GRU(64),\n",
    "    keras.layers.Dense(6, activation='sigmoid')  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34dbfe1e-3528-4063-8055-aadd794e1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the GRU model\n",
    "gru_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f20da1-ce53-48f4-aa6c-2e044723ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 488/2236 [=====>........................] - ETA: 1:33:56 - loss: 0.1625 - accuracy: 0.9135"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the CSR matrix to a NumPy array\n",
    "X_train_tfidf_array = X_train_tfidf.toarray()\n",
    "\n",
    "# Train the GRU model\n",
    "gru_model.fit(X_train_tfidf_array, y_train, epochs=5, batch_size=64, validation_split=0.2)  \n",
    " k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533535af-6beb-41c7-9d39-dfbc9a26bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the GRU model\n",
    "gru_scores = gru_model.evaluate(X_test_tfidf, y_test)\n",
    "print(\"GRU Model - Evaluation Metrics:\")\n",
    "print(f\"Loss: {gru_scores[0]}\")\n",
    "print(f\"Accuracy: {gru_scores[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53734da-6331-4b87-aa57-2a6580b7f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3edef-0b33-4462-af7e-ef88e955516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RNN model (using SimpleRNN for comparison)\n",
    "rnn_model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=5000, output_dim=128, input_length=X_train_tfidf.shape[1]),\n",
    "    keras.layers.SimpleRNN(64),\n",
    "    keras.layers.Dense(6, activation='sigmoid')  # 6 output neurons for multi-label classification\n",
    "])\n",
    "\n",
    "# Compile the RNN model\n",
    "rnn_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the RNN model\n",
    "rnn_model.fit(X_train_tfidf, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the RNN model\n",
    "rnn_scores = rnn_model.evaluate(X_test_tfidf, y_test)\n",
    "print(\"RNN Model - Evaluation Metrics:\")\n",
    "print(f\"Loss: {rnn_scores[0]}\")\n",
    "print(f\"Accuracy: {rnn_scores[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c3338-021a-4206-8eaf-fe3b0446944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM model\n",
    "lstm_model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=5000, output_dim=128, input_length=X_train_tfidf.shape[1]),\n",
    "    keras.layers.LSTM(64),\n",
    "    keras.layers.Dense(6, activation='sigmoid')  # 6 output neurons for multi-label classification\n",
    "])\n",
    "\n",
    "# Compile the LSTM model\n",
    "lstm_model.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_tfidf, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_scores = lstm_model.evaluate(X_test_tfidf, y_test)\n",
    "print(\"LSTM Model - Evaluation Metrics:\")\n",
    "print(f\"Loss: {lstm_scores[0]}\")\n",
    "print(f\"Accuracy: {lstm_scores[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
